{"ast":null,"code":"\"use strict\";\n\nvar _objectSpread = require(\"C:/Users/raphm/Documents/Projects/youtube-transcript/youtube-transcript/node_modules/@babel/runtime/helpers/objectSpread2.js\").default;\nvar _regeneratorRuntime = require(\"C:/Users/raphm/Documents/Projects/youtube-transcript/youtube-transcript/node_modules/@babel/runtime/helpers/regeneratorRuntime.js\").default;\nvar _asyncToGenerator = require(\"C:/Users/raphm/Documents/Projects/youtube-transcript/youtube-transcript/node_modules/@babel/runtime/helpers/asyncToGenerator.js\").default;\nvar _classCallCheck = require(\"C:/Users/raphm/Documents/Projects/youtube-transcript/youtube-transcript/node_modules/@babel/runtime/helpers/classCallCheck.js\").default;\nvar _createClass = require(\"C:/Users/raphm/Documents/Projects/youtube-transcript/youtube-transcript/node_modules/@babel/runtime/helpers/createClass.js\").default;\nvar _assertThisInitialized = require(\"C:/Users/raphm/Documents/Projects/youtube-transcript/youtube-transcript/node_modules/@babel/runtime/helpers/assertThisInitialized.js\").default;\nvar _inherits = require(\"C:/Users/raphm/Documents/Projects/youtube-transcript/youtube-transcript/node_modules/@babel/runtime/helpers/inherits.js\").default;\nvar _createSuper = require(\"C:/Users/raphm/Documents/Projects/youtube-transcript/youtube-transcript/node_modules/@babel/runtime/helpers/createSuper.js\").default;\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.GridFSBucketWriteStream = void 0;\nvar stream_1 = require(\"stream\");\nvar bson_1 = require(\"../bson\");\nvar error_1 = require(\"../error\");\nvar write_concern_1 = require(\"./../write_concern\");\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nvar GridFSBucketWriteStream = /*#__PURE__*/function (_stream_1$Writable) {\n  _inherits(GridFSBucketWriteStream, _stream_1$Writable);\n  var _super = _createSuper(GridFSBucketWriteStream);\n  /**\n   * @param bucket - Handle for this stream's corresponding bucket\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   * @internal\n   */\n  function GridFSBucketWriteStream(bucket, filename, options) {\n    var _options;\n    var _this;\n    _classCallCheck(this, GridFSBucketWriteStream);\n    _this = _super.call(this);\n    /**\n     * The document containing information about the inserted file.\n     * This property is defined _after_ the finish event has been emitted.\n     * It will remain `null` if an error occurs.\n     *\n     * @example\n     * ```ts\n     * fs.createReadStream('file.txt')\n     *   .pipe(bucket.openUploadStream('file.txt'))\n     *   .on('finish', function () {\n     *     console.log(this.gridFSFile)\n     *   })\n     * ```\n     */\n    _this.gridFSFile = null;\n    options = (_options = options) !== null && _options !== void 0 ? _options : {};\n    _this.bucket = bucket;\n    _this.chunks = bucket.s._chunksCollection;\n    _this.filename = filename;\n    _this.files = bucket.s._filesCollection;\n    _this.options = options;\n    _this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n    // Signals the write is all done\n    _this.done = false;\n    _this.id = options.id ? options.id : new bson_1.ObjectId();\n    // properly inherit the default chunksize from parent\n    _this.chunkSizeBytes = options.chunkSizeBytes || _this.bucket.s.options.chunkSizeBytes;\n    _this.bufToStore = Buffer.alloc(_this.chunkSizeBytes);\n    _this.length = 0;\n    _this.n = 0;\n    _this.pos = 0;\n    _this.state = {\n      streamEnd: false,\n      outstandingRequests: 0,\n      errored: false,\n      aborted: false\n    };\n    if (!_this.bucket.s.calledOpenUploadStream) {\n      _this.bucket.s.calledOpenUploadStream = true;\n      checkIndexes(_assertThisInitialized(_this)).then(function () {\n        _this.bucket.s.checkedIndexes = true;\n        _this.bucket.emit('index');\n      }, function () {\n        return null;\n      });\n    }\n    return _this;\n  }\n  /**\n   * @internal\n   *\n   * The stream is considered constructed when the indexes are done being created\n   */\n  _createClass(GridFSBucketWriteStream, [{\n    key: \"_construct\",\n    value: function _construct(callback) {\n      if (this.bucket.s.checkedIndexes) {\n        return process.nextTick(callback);\n      }\n      this.bucket.once('index', callback);\n    }\n    /**\n     * @internal\n     * Write a buffer to the stream.\n     *\n     * @param chunk - Buffer to write\n     * @param encoding - Optional encoding for the buffer\n     * @param callback - Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\n     */\n  }, {\n    key: \"_write\",\n    value: function _write(chunk, encoding, callback) {\n      doWrite(this, chunk, encoding, callback);\n    }\n    /** @internal */\n  }, {\n    key: \"_final\",\n    value: function _final(callback) {\n      if (this.state.streamEnd) {\n        return process.nextTick(callback);\n      }\n      this.state.streamEnd = true;\n      writeRemnant(this, callback);\n    }\n    /**\n     * Places this write stream into an aborted state (all future writes fail)\n     * and deletes all chunks that have already been written.\n     */\n  }, {\n    key: \"abort\",\n    value: function () {\n      var _abort = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee() {\n        return _regeneratorRuntime().wrap(function _callee$(_context) {\n          while (1) switch (_context.prev = _context.next) {\n            case 0:\n              if (!this.state.streamEnd) {\n                _context.next = 2;\n                break;\n              }\n              throw new error_1.MongoAPIError('Cannot abort a stream that has already completed');\n            case 2:\n              if (!this.state.aborted) {\n                _context.next = 4;\n                break;\n              }\n              throw new error_1.MongoAPIError('Cannot call abort() on a stream twice');\n            case 4:\n              this.state.aborted = true;\n              _context.next = 7;\n              return this.chunks.deleteMany({\n                files_id: this.id\n              });\n            case 7:\n            case \"end\":\n              return _context.stop();\n          }\n        }, _callee, this);\n      }));\n      function abort() {\n        return _abort.apply(this, arguments);\n      }\n      return abort;\n    }()\n  }]);\n  return GridFSBucketWriteStream;\n}(stream_1.Writable);\nexports.GridFSBucketWriteStream = GridFSBucketWriteStream;\nfunction handleError(stream, error, callback) {\n  if (stream.state.errored) {\n    process.nextTick(callback);\n    return;\n  }\n  stream.state.errored = true;\n  process.nextTick(callback, error);\n}\nfunction createChunkDoc(filesId, n, data) {\n  return {\n    _id: new bson_1.ObjectId(),\n    files_id: filesId,\n    n: n,\n    data: data\n  };\n}\nfunction checkChunksIndex(_x) {\n  return _checkChunksIndex.apply(this, arguments);\n}\nfunction _checkChunksIndex() {\n  _checkChunksIndex = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(stream) {\n    var index, indexes, hasChunksIndex;\n    return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n      while (1) switch (_context2.prev = _context2.next) {\n        case 0:\n          index = {\n            files_id: 1,\n            n: 1\n          };\n          _context2.prev = 1;\n          _context2.next = 4;\n          return stream.chunks.listIndexes().toArray();\n        case 4:\n          indexes = _context2.sent;\n          _context2.next = 14;\n          break;\n        case 7:\n          _context2.prev = 7;\n          _context2.t0 = _context2[\"catch\"](1);\n          if (!(_context2.t0 instanceof error_1.MongoError && _context2.t0.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound)) {\n            _context2.next = 13;\n            break;\n          }\n          indexes = [];\n          _context2.next = 14;\n          break;\n        case 13:\n          throw _context2.t0;\n        case 14:\n          hasChunksIndex = !!indexes.find(function (index) {\n            var keys = Object.keys(index.key);\n            if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n              return true;\n            }\n            return false;\n          });\n          if (hasChunksIndex) {\n            _context2.next = 18;\n            break;\n          }\n          _context2.next = 18;\n          return stream.chunks.createIndex(index, _objectSpread(_objectSpread({}, stream.writeConcern), {}, {\n            background: true,\n            unique: true\n          }));\n        case 18:\n        case \"end\":\n          return _context2.stop();\n      }\n    }, _callee2, null, [[1, 7]]);\n  }));\n  return _checkChunksIndex.apply(this, arguments);\n}\nfunction checkDone(stream, callback) {\n  if (stream.done) {\n    return process.nextTick(callback);\n  }\n  if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n    // Set done so we do not trigger duplicate createFilesDoc\n    stream.done = true;\n    // Create a new files doc\n    var gridFSFile = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);\n    if (isAborted(stream, callback)) {\n      return;\n    }\n    stream.files.insertOne(gridFSFile, {\n      writeConcern: stream.writeConcern\n    }).then(function () {\n      stream.gridFSFile = gridFSFile;\n      callback();\n    }, function (error) {\n      return handleError(stream, error, callback);\n    });\n    return;\n  }\n  process.nextTick(callback);\n}\nfunction checkIndexes(_x2) {\n  return _checkIndexes.apply(this, arguments);\n}\nfunction _checkIndexes() {\n  _checkIndexes = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3(stream) {\n    var doc, index, indexes, hasFileIndex;\n    return _regeneratorRuntime().wrap(function _callee3$(_context3) {\n      while (1) switch (_context3.prev = _context3.next) {\n        case 0:\n          _context3.next = 2;\n          return stream.files.findOne({}, {\n            projection: {\n              _id: 1\n            }\n          });\n        case 2:\n          doc = _context3.sent;\n          if (!(doc != null)) {\n            _context3.next = 5;\n            break;\n          }\n          return _context3.abrupt(\"return\");\n        case 5:\n          index = {\n            filename: 1,\n            uploadDate: 1\n          };\n          _context3.prev = 6;\n          _context3.next = 9;\n          return stream.files.listIndexes().toArray();\n        case 9:\n          indexes = _context3.sent;\n          _context3.next = 19;\n          break;\n        case 12:\n          _context3.prev = 12;\n          _context3.t0 = _context3[\"catch\"](6);\n          if (!(_context3.t0 instanceof error_1.MongoError && _context3.t0.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound)) {\n            _context3.next = 18;\n            break;\n          }\n          indexes = [];\n          _context3.next = 19;\n          break;\n        case 18:\n          throw _context3.t0;\n        case 19:\n          hasFileIndex = !!indexes.find(function (index) {\n            var keys = Object.keys(index.key);\n            if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n              return true;\n            }\n            return false;\n          });\n          if (hasFileIndex) {\n            _context3.next = 23;\n            break;\n          }\n          _context3.next = 23;\n          return stream.files.createIndex(index, {\n            background: false\n          });\n        case 23:\n          _context3.next = 25;\n          return checkChunksIndex(stream);\n        case 25:\n        case \"end\":\n          return _context3.stop();\n      }\n    }, _callee3, null, [[6, 12]]);\n  }));\n  return _checkIndexes.apply(this, arguments);\n}\nfunction createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {\n  var ret = {\n    _id: _id,\n    length: length,\n    chunkSize: chunkSize,\n    uploadDate: new Date(),\n    filename: filename\n  };\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n  return ret;\n}\nfunction doWrite(stream, chunk, encoding, callback) {\n  if (isAborted(stream, callback)) {\n    return;\n  }\n  var inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n  stream.length += inputBuf.length;\n  // Input is small enough to fit in our buffer\n  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n    inputBuf.copy(stream.bufToStore, stream.pos);\n    stream.pos += inputBuf.length;\n    process.nextTick(callback);\n    return;\n  }\n  // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n  var inputBufRemaining = inputBuf.length;\n  var spaceRemaining = stream.chunkSizeBytes - stream.pos;\n  var numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  var outstandingRequests = 0;\n  while (inputBufRemaining > 0) {\n    var inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n    stream.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n    var doc = void 0;\n    if (spaceRemaining === 0) {\n      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n      ++stream.state.outstandingRequests;\n      ++outstandingRequests;\n      if (isAborted(stream, callback)) {\n        return;\n      }\n      stream.chunks.insertOne(doc, {\n        writeConcern: stream.writeConcern\n      }).then(function () {\n        --stream.state.outstandingRequests;\n        --outstandingRequests;\n        if (!outstandingRequests) {\n          checkDone(stream, callback);\n        }\n      }, function (error) {\n        return handleError(stream, error, callback);\n      });\n      spaceRemaining = stream.chunkSizeBytes;\n      stream.pos = 0;\n      ++stream.n;\n    }\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  }\n}\nfunction writeRemnant(stream, callback) {\n  // Buffer is empty, so don't bother to insert\n  if (stream.pos === 0) {\n    return checkDone(stream, callback);\n  }\n  ++stream.state.outstandingRequests;\n  // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n  var remnant = Buffer.alloc(stream.pos);\n  stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n  var doc = createChunkDoc(stream.id, stream.n, remnant);\n  // If the stream was aborted, do not write remnant\n  if (isAborted(stream, callback)) {\n    return;\n  }\n  stream.chunks.insertOne(doc, {\n    writeConcern: stream.writeConcern\n  }).then(function () {\n    --stream.state.outstandingRequests;\n    checkDone(stream, callback);\n  }, function (error) {\n    return handleError(stream, error, callback);\n  });\n}\nfunction isAborted(stream, callback) {\n  if (stream.state.aborted) {\n    process.nextTick(callback, new error_1.MongoAPIError('Stream has been aborted'));\n    return true;\n  }\n  return false;\n}","map":{"version":3,"names":["stream_1","require","bson_1","error_1","write_concern_1","GridFSBucketWriteStream","_stream_1$Writable","_inherits","_super","_createSuper","bucket","filename","options","_options","_this","_classCallCheck","call","gridFSFile","chunks","s","_chunksCollection","files","_filesCollection","writeConcern","WriteConcern","fromOptions","done","id","ObjectId","chunkSizeBytes","bufToStore","Buffer","alloc","length","n","pos","state","streamEnd","outstandingRequests","errored","aborted","calledOpenUploadStream","checkIndexes","_assertThisInitialized","then","checkedIndexes","emit","_createClass","key","value","_construct","callback","process","nextTick","once","_write","chunk","encoding","doWrite","_final","writeRemnant","_abort","_asyncToGenerator","_regeneratorRuntime","mark","_callee","wrap","_callee$","_context","prev","next","MongoAPIError","deleteMany","files_id","stop","abort","apply","arguments","Writable","exports","handleError","stream","error","createChunkDoc","filesId","data","_id","checkChunksIndex","_x","_checkChunksIndex","_callee2","index","indexes","hasChunksIndex","_callee2$","_context2","listIndexes","toArray","sent","t0","MongoError","code","MONGODB_ERROR_CODES","NamespaceNotFound","find","keys","Object","createIndex","_objectSpread","background","unique","checkDone","createFilesDoc","contentType","aliases","metadata","isAborted","insertOne","_x2","_checkIndexes","_callee3","doc","hasFileIndex","_callee3$","_context3","findOne","projection","abrupt","uploadDate","chunkSize","ret","Date","inputBuf","isBuffer","from","copy","inputBufRemaining","spaceRemaining","numToCopy","Math","min","inputBufPos","remnant"],"sources":["C:\\Users\\raphm\\Documents\\Projects\\youtube-transcript\\youtube-transcript\\node_modules\\mongodb\\src\\gridfs\\upload.ts"],"sourcesContent":["import { Writable } from 'stream';\n\nimport type { Document } from '../bson';\nimport { ObjectId } from '../bson';\nimport type { Collection } from '../collection';\nimport { MongoAPIError, MONGODB_ERROR_CODES, MongoError } from '../error';\nimport type { Callback } from '../utils';\nimport type { WriteConcernOptions } from '../write_concern';\nimport { WriteConcern } from './../write_concern';\nimport type { GridFSFile } from './download';\nimport type { GridFSBucket } from './index';\n\n/** @public */\nexport interface GridFSChunk {\n  _id: ObjectId;\n  files_id: ObjectId;\n  n: number;\n  data: Buffer | Uint8Array;\n}\n\n/** @public */\nexport interface GridFSBucketWriteStreamOptions extends WriteConcernOptions {\n  /** Overwrite this bucket's chunkSizeBytes for this file */\n  chunkSizeBytes?: number;\n  /** Custom file id for the GridFS file. */\n  id?: ObjectId;\n  /** Object to store in the file document's `metadata` field */\n  metadata?: Document;\n  /** String to store in the file document's `contentType` field */\n  contentType?: string;\n  /** Array of strings to store in the file document's `aliases` field */\n  aliases?: string[];\n}\n\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nexport class GridFSBucketWriteStream extends Writable {\n  bucket: GridFSBucket;\n  /** A Collection instance where the file's chunks are stored */\n  chunks: Collection<GridFSChunk>;\n  /** A Collection instance where the file's GridFSFile document is stored */\n  files: Collection<GridFSFile>;\n  /** The name of the file */\n  filename: string;\n  /** Options controlling the metadata inserted along with the file */\n  options: GridFSBucketWriteStreamOptions;\n  /** Indicates the stream is finished uploading */\n  done: boolean;\n  /** The ObjectId used for the `_id` field on the GridFSFile document */\n  id: ObjectId;\n  /** The number of bytes that each chunk will be limited to */\n  chunkSizeBytes: number;\n  /** Space used to store a chunk currently being inserted */\n  bufToStore: Buffer;\n  /** Accumulates the number of bytes inserted as the stream uploads chunks */\n  length: number;\n  /** Accumulates the number of chunks inserted as the stream uploads file contents */\n  n: number;\n  /** Tracks the current offset into the buffered bytes being uploaded */\n  pos: number;\n  /** Contains a number of properties indicating the current state of the stream */\n  state: {\n    /** If set the stream has ended */\n    streamEnd: boolean;\n    /** Indicates the number of chunks that still need to be inserted to exhaust the current buffered data */\n    outstandingRequests: number;\n    /** If set an error occurred during insertion */\n    errored: boolean;\n    /** If set the stream was intentionally aborted */\n    aborted: boolean;\n  };\n  /** The write concern setting to be used with every insert operation */\n  writeConcern?: WriteConcern;\n  /**\n   * The document containing information about the inserted file.\n   * This property is defined _after_ the finish event has been emitted.\n   * It will remain `null` if an error occurs.\n   *\n   * @example\n   * ```ts\n   * fs.createReadStream('file.txt')\n   *   .pipe(bucket.openUploadStream('file.txt'))\n   *   .on('finish', function () {\n   *     console.log(this.gridFSFile)\n   *   })\n   * ```\n   */\n  gridFSFile: GridFSFile | null = null;\n\n  /**\n   * @param bucket - Handle for this stream's corresponding bucket\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   * @internal\n   */\n  constructor(bucket: GridFSBucket, filename: string, options?: GridFSBucketWriteStreamOptions) {\n    super();\n\n    options = options ?? {};\n    this.bucket = bucket;\n    this.chunks = bucket.s._chunksCollection;\n    this.filename = filename;\n    this.files = bucket.s._filesCollection;\n    this.options = options;\n    this.writeConcern = WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n    // Signals the write is all done\n    this.done = false;\n\n    this.id = options.id ? options.id : new ObjectId();\n    // properly inherit the default chunksize from parent\n    this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n    this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n    this.length = 0;\n    this.n = 0;\n    this.pos = 0;\n    this.state = {\n      streamEnd: false,\n      outstandingRequests: 0,\n      errored: false,\n      aborted: false\n    };\n\n    if (!this.bucket.s.calledOpenUploadStream) {\n      this.bucket.s.calledOpenUploadStream = true;\n\n      checkIndexes(this).then(\n        () => {\n          this.bucket.s.checkedIndexes = true;\n          this.bucket.emit('index');\n        },\n        () => null\n      );\n    }\n  }\n\n  /**\n   * @internal\n   *\n   * The stream is considered constructed when the indexes are done being created\n   */\n  override _construct(callback: (error?: Error | null) => void): void {\n    if (this.bucket.s.checkedIndexes) {\n      return process.nextTick(callback);\n    }\n    this.bucket.once('index', callback);\n  }\n\n  /**\n   * @internal\n   * Write a buffer to the stream.\n   *\n   * @param chunk - Buffer to write\n   * @param encoding - Optional encoding for the buffer\n   * @param callback - Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\n   */\n  override _write(\n    chunk: Buffer | string,\n    encoding: BufferEncoding,\n    callback: Callback<void>\n  ): void {\n    doWrite(this, chunk, encoding, callback);\n  }\n\n  /** @internal */\n  override _final(callback: (error?: Error | null) => void): void {\n    if (this.state.streamEnd) {\n      return process.nextTick(callback);\n    }\n    this.state.streamEnd = true;\n    writeRemnant(this, callback);\n  }\n\n  /**\n   * Places this write stream into an aborted state (all future writes fail)\n   * and deletes all chunks that have already been written.\n   */\n  async abort(): Promise<void> {\n    if (this.state.streamEnd) {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n      throw new MongoAPIError('Cannot abort a stream that has already completed');\n    }\n\n    if (this.state.aborted) {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n      throw new MongoAPIError('Cannot call abort() on a stream twice');\n    }\n\n    this.state.aborted = true;\n    await this.chunks.deleteMany({ files_id: this.id });\n  }\n}\n\nfunction handleError(stream: GridFSBucketWriteStream, error: Error, callback: Callback): void {\n  if (stream.state.errored) {\n    process.nextTick(callback);\n    return;\n  }\n  stream.state.errored = true;\n  process.nextTick(callback, error);\n}\n\nfunction createChunkDoc(filesId: ObjectId, n: number, data: Buffer): GridFSChunk {\n  return {\n    _id: new ObjectId(),\n    files_id: filesId,\n    n,\n    data\n  };\n}\n\nasync function checkChunksIndex(stream: GridFSBucketWriteStream): Promise<void> {\n  const index = { files_id: 1, n: 1 };\n\n  let indexes;\n  try {\n    indexes = await stream.chunks.listIndexes().toArray();\n  } catch (error) {\n    if (error instanceof MongoError && error.code === MONGODB_ERROR_CODES.NamespaceNotFound) {\n      indexes = [];\n    } else {\n      throw error;\n    }\n  }\n\n  const hasChunksIndex = !!indexes.find(index => {\n    const keys = Object.keys(index.key);\n    if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n      return true;\n    }\n    return false;\n  });\n\n  if (!hasChunksIndex) {\n    await stream.chunks.createIndex(index, {\n      ...stream.writeConcern,\n      background: true,\n      unique: true\n    });\n  }\n}\n\nfunction checkDone(stream: GridFSBucketWriteStream, callback: Callback): void {\n  if (stream.done) {\n    return process.nextTick(callback);\n  }\n\n  if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n    // Set done so we do not trigger duplicate createFilesDoc\n    stream.done = true;\n    // Create a new files doc\n    const gridFSFile = createFilesDoc(\n      stream.id,\n      stream.length,\n      stream.chunkSizeBytes,\n      stream.filename,\n      stream.options.contentType,\n      stream.options.aliases,\n      stream.options.metadata\n    );\n\n    if (isAborted(stream, callback)) {\n      return;\n    }\n\n    stream.files.insertOne(gridFSFile, { writeConcern: stream.writeConcern }).then(\n      () => {\n        stream.gridFSFile = gridFSFile;\n        callback();\n      },\n      error => handleError(stream, error, callback)\n    );\n    return;\n  }\n\n  process.nextTick(callback);\n}\n\nasync function checkIndexes(stream: GridFSBucketWriteStream): Promise<void> {\n  const doc = await stream.files.findOne({}, { projection: { _id: 1 } });\n  if (doc != null) {\n    // If at least one document exists assume the collection has the required index\n    return;\n  }\n\n  const index = { filename: 1, uploadDate: 1 };\n\n  let indexes;\n  try {\n    indexes = await stream.files.listIndexes().toArray();\n  } catch (error) {\n    if (error instanceof MongoError && error.code === MONGODB_ERROR_CODES.NamespaceNotFound) {\n      indexes = [];\n    } else {\n      throw error;\n    }\n  }\n\n  const hasFileIndex = !!indexes.find(index => {\n    const keys = Object.keys(index.key);\n    if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n      return true;\n    }\n    return false;\n  });\n\n  if (!hasFileIndex) {\n    await stream.files.createIndex(index, { background: false });\n  }\n\n  await checkChunksIndex(stream);\n}\n\nfunction createFilesDoc(\n  _id: ObjectId,\n  length: number,\n  chunkSize: number,\n  filename: string,\n  contentType?: string,\n  aliases?: string[],\n  metadata?: Document\n): GridFSFile {\n  const ret: GridFSFile = {\n    _id,\n    length,\n    chunkSize,\n    uploadDate: new Date(),\n    filename\n  };\n\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n\n  return ret;\n}\n\nfunction doWrite(\n  stream: GridFSBucketWriteStream,\n  chunk: Buffer | string,\n  encoding: BufferEncoding,\n  callback: Callback<void>\n): void {\n  if (isAborted(stream, callback)) {\n    return;\n  }\n\n  const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n\n  stream.length += inputBuf.length;\n\n  // Input is small enough to fit in our buffer\n  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n    inputBuf.copy(stream.bufToStore, stream.pos);\n    stream.pos += inputBuf.length;\n    process.nextTick(callback);\n    return;\n  }\n\n  // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n  let inputBufRemaining = inputBuf.length;\n  let spaceRemaining: number = stream.chunkSizeBytes - stream.pos;\n  let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  let outstandingRequests = 0;\n  while (inputBufRemaining > 0) {\n    const inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n    stream.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n    let doc: GridFSChunk;\n    if (spaceRemaining === 0) {\n      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n      ++stream.state.outstandingRequests;\n      ++outstandingRequests;\n\n      if (isAborted(stream, callback)) {\n        return;\n      }\n\n      stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(\n        () => {\n          --stream.state.outstandingRequests;\n          --outstandingRequests;\n\n          if (!outstandingRequests) {\n            checkDone(stream, callback);\n          }\n        },\n        error => handleError(stream, error, callback)\n      );\n\n      spaceRemaining = stream.chunkSizeBytes;\n      stream.pos = 0;\n      ++stream.n;\n    }\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  }\n}\n\nfunction writeRemnant(stream: GridFSBucketWriteStream, callback: Callback): void {\n  // Buffer is empty, so don't bother to insert\n  if (stream.pos === 0) {\n    return checkDone(stream, callback);\n  }\n\n  ++stream.state.outstandingRequests;\n\n  // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n  const remnant = Buffer.alloc(stream.pos);\n  stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n  const doc = createChunkDoc(stream.id, stream.n, remnant);\n\n  // If the stream was aborted, do not write remnant\n  if (isAborted(stream, callback)) {\n    return;\n  }\n\n  stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(\n    () => {\n      --stream.state.outstandingRequests;\n      checkDone(stream, callback);\n    },\n    error => handleError(stream, error, callback)\n  );\n}\n\nfunction isAborted(stream: GridFSBucketWriteStream, callback: Callback<void>): boolean {\n  if (stream.state.aborted) {\n    process.nextTick(callback, new MongoAPIError('Stream has been aborted'));\n    return true;\n  }\n  return false;\n}\n"],"mappings":";;;;;;;;;;;;;;AAAA,IAAAA,QAAA,GAAAC,OAAA;AAGA,IAAAC,MAAA,GAAAD,OAAA;AAEA,IAAAE,OAAA,GAAAF,OAAA;AAGA,IAAAG,eAAA,GAAAH,OAAA;AA0BA;;;;;;AAAA,IAMaI,uBAAwB,0BAAAC,kBAAA;EAAAC,SAAA,CAAAF,uBAAA,EAAAC,kBAAA;EAAA,IAAAE,MAAA,GAAAC,YAAA,CAAAJ,uBAAA;EAqDnC;;;;;;EAMA,SAAAA,wBAAYK,MAAoB,EAAEC,QAAgB,EAAEC,OAAwC;IAAA,IAAAC,QAAA;IAAA,IAAAC,KAAA;IAAAC,eAAA,OAAAV,uBAAA;IAC1FS,KAAA,GAAAN,MAAA,CAAAQ,IAAA;IAvBF;;;;;;;;;;;;;;IAcAF,KAAA,CAAAG,UAAU,GAAsB,IAAI;IAWlCL,OAAO,IAAAC,QAAA,GAAGD,OAAO,cAAAC,QAAA,cAAAA,QAAA,GAAI,EAAE;IACvBC,KAAA,CAAKJ,MAAM,GAAGA,MAAM;IACpBI,KAAA,CAAKI,MAAM,GAAGR,MAAM,CAACS,CAAC,CAACC,iBAAiB;IACxCN,KAAA,CAAKH,QAAQ,GAAGA,QAAQ;IACxBG,KAAA,CAAKO,KAAK,GAAGX,MAAM,CAACS,CAAC,CAACG,gBAAgB;IACtCR,KAAA,CAAKF,OAAO,GAAGA,OAAO;IACtBE,KAAA,CAAKS,YAAY,GAAGnB,eAAA,CAAAoB,YAAY,CAACC,WAAW,CAACb,OAAO,CAAC,IAAIF,MAAM,CAACS,CAAC,CAACP,OAAO,CAACW,YAAY;IACtF;IACAT,KAAA,CAAKY,IAAI,GAAG,KAAK;IAEjBZ,KAAA,CAAKa,EAAE,GAAGf,OAAO,CAACe,EAAE,GAAGf,OAAO,CAACe,EAAE,GAAG,IAAIzB,MAAA,CAAA0B,QAAQ,EAAE;IAClD;IACAd,KAAA,CAAKe,cAAc,GAAGjB,OAAO,CAACiB,cAAc,IAAIf,KAAA,CAAKJ,MAAM,CAACS,CAAC,CAACP,OAAO,CAACiB,cAAc;IACpFf,KAAA,CAAKgB,UAAU,GAAGC,MAAM,CAACC,KAAK,CAAClB,KAAA,CAAKe,cAAc,CAAC;IACnDf,KAAA,CAAKmB,MAAM,GAAG,CAAC;IACfnB,KAAA,CAAKoB,CAAC,GAAG,CAAC;IACVpB,KAAA,CAAKqB,GAAG,GAAG,CAAC;IACZrB,KAAA,CAAKsB,KAAK,GAAG;MACXC,SAAS,EAAE,KAAK;MAChBC,mBAAmB,EAAE,CAAC;MACtBC,OAAO,EAAE,KAAK;MACdC,OAAO,EAAE;KACV;IAED,IAAI,CAAC1B,KAAA,CAAKJ,MAAM,CAACS,CAAC,CAACsB,sBAAsB,EAAE;MACzC3B,KAAA,CAAKJ,MAAM,CAACS,CAAC,CAACsB,sBAAsB,GAAG,IAAI;MAE3CC,YAAY,CAAAC,sBAAA,CAAA7B,KAAA,CAAK,CAAC,CAAC8B,IAAI,CACrB,YAAK;QACH9B,KAAA,CAAKJ,MAAM,CAACS,CAAC,CAAC0B,cAAc,GAAG,IAAI;QACnC/B,KAAA,CAAKJ,MAAM,CAACoC,IAAI,CAAC,OAAO,CAAC;MAC3B,CAAC,EACD;QAAA,OAAM,IAAI;MAAA,EACX;;IACF,OAAAhC,KAAA;EACH;EAEA;;;;;EAAAiC,YAAA,CAAA1C,uBAAA;IAAA2C,GAAA;IAAAC,KAAA,EAKS,SAAAC,WAAWC,QAAwC;MAC1D,IAAI,IAAI,CAACzC,MAAM,CAACS,CAAC,CAAC0B,cAAc,EAAE;QAChC,OAAOO,OAAO,CAACC,QAAQ,CAACF,QAAQ,CAAC;;MAEnC,IAAI,CAACzC,MAAM,CAAC4C,IAAI,CAAC,OAAO,EAAEH,QAAQ,CAAC;IACrC;IAEA;;;;;;;;EAAA;IAAAH,GAAA;IAAAC,KAAA,EAQS,SAAAM,OACPC,KAAsB,EACtBC,QAAwB,EACxBN,QAAwB;MAExBO,OAAO,CAAC,IAAI,EAAEF,KAAK,EAAEC,QAAQ,EAAEN,QAAQ,CAAC;IAC1C;IAEA;EAAA;IAAAH,GAAA;IAAAC,KAAA,EACS,SAAAU,OAAOR,QAAwC;MACtD,IAAI,IAAI,CAACf,KAAK,CAACC,SAAS,EAAE;QACxB,OAAOe,OAAO,CAACC,QAAQ,CAACF,QAAQ,CAAC;;MAEnC,IAAI,CAACf,KAAK,CAACC,SAAS,GAAG,IAAI;MAC3BuB,YAAY,CAAC,IAAI,EAAET,QAAQ,CAAC;IAC9B;IAEA;;;;EAAA;IAAAH,GAAA;IAAAC,KAAA;MAAA,IAAAY,MAAA,GAAAC,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAIA,SAAAC,QAAA;QAAA,OAAAF,mBAAA,GAAAG,IAAA,UAAAC,SAAAC,QAAA;UAAA,kBAAAA,QAAA,CAAAC,IAAA,GAAAD,QAAA,CAAAE,IAAA;YAAA;cAAA,KACM,IAAI,CAAClC,KAAK,CAACC,SAAS;gBAAA+B,QAAA,CAAAE,IAAA;gBAAA;cAAA;cAAA,MAEhB,IAAInE,OAAA,CAAAoE,aAAa,CAAC,kDAAkD,CAAC;YAAA;cAAA,KAGzE,IAAI,CAACnC,KAAK,CAACI,OAAO;gBAAA4B,QAAA,CAAAE,IAAA;gBAAA;cAAA;cAAA,MAEd,IAAInE,OAAA,CAAAoE,aAAa,CAAC,uCAAuC,CAAC;YAAA;cAGlE,IAAI,CAACnC,KAAK,CAACI,OAAO,GAAG,IAAI;cAAC4B,QAAA,CAAAE,IAAA;cAAA,OACpB,IAAI,CAACpD,MAAM,CAACsD,UAAU,CAAC;gBAAEC,QAAQ,EAAE,IAAI,CAAC9C;cAAE,CAAE,CAAC;YAAA;YAAA;cAAA,OAAAyC,QAAA,CAAAM,IAAA;UAAA;QAAA,GAAAT,OAAA;MAAA,CACpD;MAAA,SAAAU,MAAA;QAAA,OAAAd,MAAA,CAAAe,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAAF,KAAA;IAAA;EAAA;EAAA,OAAAtE,uBAAA;AAAA,EAzJ0CL,QAAA,CAAA8E,QAAQ;AAArDC,OAAA,CAAA1E,uBAAA,GAAAA,uBAAA;AA4JA,SAAS2E,WAAWA,CAACC,MAA+B,EAAEC,KAAY,EAAE/B,QAAkB;EACpF,IAAI8B,MAAM,CAAC7C,KAAK,CAACG,OAAO,EAAE;IACxBa,OAAO,CAACC,QAAQ,CAACF,QAAQ,CAAC;IAC1B;;EAEF8B,MAAM,CAAC7C,KAAK,CAACG,OAAO,GAAG,IAAI;EAC3Ba,OAAO,CAACC,QAAQ,CAACF,QAAQ,EAAE+B,KAAK,CAAC;AACnC;AAEA,SAASC,cAAcA,CAACC,OAAiB,EAAElD,CAAS,EAAEmD,IAAY;EAChE,OAAO;IACLC,GAAG,EAAE,IAAIpF,MAAA,CAAA0B,QAAQ,EAAE;IACnB6C,QAAQ,EAAEW,OAAO;IACjBlD,CAAC,EAADA,CAAC;IACDmD,IAAI,EAAJA;GACD;AACH;AAAC,SAEcE,gBAAgBA,CAAAC,EAAA;EAAA,OAAAC,iBAAA,CAAAb,KAAA,OAAAC,SAAA;AAAA;AAAA,SAAAY,kBAAA;EAAAA,iBAAA,GAAA3B,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAA/B,SAAA0B,SAAgCT,MAA+B;IAAA,IAAAU,KAAA,EAAAC,OAAA,EAAAC,cAAA;IAAA,OAAA9B,mBAAA,GAAAG,IAAA,UAAA4B,UAAAC,SAAA;MAAA,kBAAAA,SAAA,CAAA1B,IAAA,GAAA0B,SAAA,CAAAzB,IAAA;QAAA;UACvDqB,KAAK,GAAG;YAAElB,QAAQ,EAAE,CAAC;YAAEvC,CAAC,EAAE;UAAC,CAAE;UAAA6D,SAAA,CAAA1B,IAAA;UAAA0B,SAAA,CAAAzB,IAAA;UAAA,OAIjBW,MAAM,CAAC/D,MAAM,CAAC8E,WAAW,EAAE,CAACC,OAAO,EAAE;QAAA;UAArDL,OAAO,GAAAG,SAAA,CAAAG,IAAA;UAAAH,SAAA,CAAAzB,IAAA;UAAA;QAAA;UAAAyB,SAAA,CAAA1B,IAAA;UAAA0B,SAAA,CAAAI,EAAA,GAAAJ,SAAA;UAAA,MAEHA,SAAA,CAAAI,EAAA,YAAiBhG,OAAA,CAAAiG,UAAU,IAAIL,SAAA,CAAAI,EAAA,CAAME,IAAI,KAAKlG,OAAA,CAAAmG,mBAAmB,CAACC,iBAAiB;YAAAR,SAAA,CAAAzB,IAAA;YAAA;UAAA;UACrFsB,OAAO,GAAG,EAAE;UAACG,SAAA,CAAAzB,IAAA;UAAA;QAAA;UAAA,MAAAyB,SAAA,CAAAI,EAAA;QAAA;UAMXN,cAAc,GAAG,CAAC,CAACD,OAAO,CAACY,IAAI,CAAC,UAAAb,KAAK,EAAG;YAC5C,IAAMc,IAAI,GAAGC,MAAM,CAACD,IAAI,CAACd,KAAK,CAAC3C,GAAG,CAAC;YACnC,IAAIyD,IAAI,CAACxE,MAAM,KAAK,CAAC,IAAI0D,KAAK,CAAC3C,GAAG,CAACyB,QAAQ,KAAK,CAAC,IAAIkB,KAAK,CAAC3C,GAAG,CAACd,CAAC,KAAK,CAAC,EAAE;cACtE,OAAO,IAAI;;YAEb,OAAO,KAAK;UACd,CAAC,CAAC;UAAA,IAEG2D,cAAc;YAAAE,SAAA,CAAAzB,IAAA;YAAA;UAAA;UAAAyB,SAAA,CAAAzB,IAAA;UAAA,OACXW,MAAM,CAAC/D,MAAM,CAACyF,WAAW,CAAChB,KAAK,EAAAiB,aAAA,CAAAA,aAAA,KAChC3B,MAAM,CAAC1D,YAAY;YACtBsF,UAAU,EAAE,IAAI;YAChBC,MAAM,EAAE;UAAI,EACb,CAAC;QAAA;QAAA;UAAA,OAAAf,SAAA,CAAArB,IAAA;MAAA;IAAA,GAAAgB,QAAA;EAAA,CAEL;EAAA,OAAAD,iBAAA,CAAAb,KAAA,OAAAC,SAAA;AAAA;AAED,SAASkC,SAASA,CAAC9B,MAA+B,EAAE9B,QAAkB;EACpE,IAAI8B,MAAM,CAACvD,IAAI,EAAE;IACf,OAAO0B,OAAO,CAACC,QAAQ,CAACF,QAAQ,CAAC;;EAGnC,IAAI8B,MAAM,CAAC7C,KAAK,CAACC,SAAS,IAAI4C,MAAM,CAAC7C,KAAK,CAACE,mBAAmB,KAAK,CAAC,IAAI,CAAC2C,MAAM,CAAC7C,KAAK,CAACG,OAAO,EAAE;IAC7F;IACA0C,MAAM,CAACvD,IAAI,GAAG,IAAI;IAClB;IACA,IAAMT,UAAU,GAAG+F,cAAc,CAC/B/B,MAAM,CAACtD,EAAE,EACTsD,MAAM,CAAChD,MAAM,EACbgD,MAAM,CAACpD,cAAc,EACrBoD,MAAM,CAACtE,QAAQ,EACfsE,MAAM,CAACrE,OAAO,CAACqG,WAAW,EAC1BhC,MAAM,CAACrE,OAAO,CAACsG,OAAO,EACtBjC,MAAM,CAACrE,OAAO,CAACuG,QAAQ,CACxB;IAED,IAAIC,SAAS,CAACnC,MAAM,EAAE9B,QAAQ,CAAC,EAAE;MAC/B;;IAGF8B,MAAM,CAAC5D,KAAK,CAACgG,SAAS,CAACpG,UAAU,EAAE;MAAEM,YAAY,EAAE0D,MAAM,CAAC1D;IAAY,CAAE,CAAC,CAACqB,IAAI,CAC5E,YAAK;MACHqC,MAAM,CAAChE,UAAU,GAAGA,UAAU;MAC9BkC,QAAQ,EAAE;IACZ,CAAC,EACD,UAAA+B,KAAK;MAAA,OAAIF,WAAW,CAACC,MAAM,EAAEC,KAAK,EAAE/B,QAAQ,CAAC;IAAA,EAC9C;IACD;;EAGFC,OAAO,CAACC,QAAQ,CAACF,QAAQ,CAAC;AAC5B;AAAC,SAEcT,YAAYA,CAAA4E,GAAA;EAAA,OAAAC,aAAA,CAAA3C,KAAA,OAAAC,SAAA;AAAA;AAAA,SAAA0C,cAAA;EAAAA,aAAA,GAAAzD,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAA3B,SAAAwD,SAA4BvC,MAA+B;IAAA,IAAAwC,GAAA,EAAA9B,KAAA,EAAAC,OAAA,EAAA8B,YAAA;IAAA,OAAA3D,mBAAA,GAAAG,IAAA,UAAAyD,UAAAC,SAAA;MAAA,kBAAAA,SAAA,CAAAvD,IAAA,GAAAuD,SAAA,CAAAtD,IAAA;QAAA;UAAAsD,SAAA,CAAAtD,IAAA;UAAA,OACvCW,MAAM,CAAC5D,KAAK,CAACwG,OAAO,CAAC,EAAE,EAAE;YAAEC,UAAU,EAAE;cAAExC,GAAG,EAAE;YAAC;UAAE,CAAE,CAAC;QAAA;UAAhEmC,GAAG,GAAAG,SAAA,CAAA1B,IAAA;UAAA,MACLuB,GAAG,IAAI,IAAI;YAAAG,SAAA,CAAAtD,IAAA;YAAA;UAAA;UAAA,OAAAsD,SAAA,CAAAG,MAAA;QAAA;UAKTpC,KAAK,GAAG;YAAEhF,QAAQ,EAAE,CAAC;YAAEqH,UAAU,EAAE;UAAC,CAAE;UAAAJ,SAAA,CAAAvD,IAAA;UAAAuD,SAAA,CAAAtD,IAAA;UAAA,OAI1BW,MAAM,CAAC5D,KAAK,CAAC2E,WAAW,EAAE,CAACC,OAAO,EAAE;QAAA;UAApDL,OAAO,GAAAgC,SAAA,CAAA1B,IAAA;UAAA0B,SAAA,CAAAtD,IAAA;UAAA;QAAA;UAAAsD,SAAA,CAAAvD,IAAA;UAAAuD,SAAA,CAAAzB,EAAA,GAAAyB,SAAA;UAAA,MAEHA,SAAA,CAAAzB,EAAA,YAAiBhG,OAAA,CAAAiG,UAAU,IAAIwB,SAAA,CAAAzB,EAAA,CAAME,IAAI,KAAKlG,OAAA,CAAAmG,mBAAmB,CAACC,iBAAiB;YAAAqB,SAAA,CAAAtD,IAAA;YAAA;UAAA;UACrFsB,OAAO,GAAG,EAAE;UAACgC,SAAA,CAAAtD,IAAA;UAAA;QAAA;UAAA,MAAAsD,SAAA,CAAAzB,EAAA;QAAA;UAMXuB,YAAY,GAAG,CAAC,CAAC9B,OAAO,CAACY,IAAI,CAAC,UAAAb,KAAK,EAAG;YAC1C,IAAMc,IAAI,GAAGC,MAAM,CAACD,IAAI,CAACd,KAAK,CAAC3C,GAAG,CAAC;YACnC,IAAIyD,IAAI,CAACxE,MAAM,KAAK,CAAC,IAAI0D,KAAK,CAAC3C,GAAG,CAACrC,QAAQ,KAAK,CAAC,IAAIgF,KAAK,CAAC3C,GAAG,CAACgF,UAAU,KAAK,CAAC,EAAE;cAC/E,OAAO,IAAI;;YAEb,OAAO,KAAK;UACd,CAAC,CAAC;UAAA,IAEGN,YAAY;YAAAE,SAAA,CAAAtD,IAAA;YAAA;UAAA;UAAAsD,SAAA,CAAAtD,IAAA;UAAA,OACTW,MAAM,CAAC5D,KAAK,CAACsF,WAAW,CAAChB,KAAK,EAAE;YAAEkB,UAAU,EAAE;UAAK,CAAE,CAAC;QAAA;UAAAe,SAAA,CAAAtD,IAAA;UAAA,OAGxDiB,gBAAgB,CAACN,MAAM,CAAC;QAAA;QAAA;UAAA,OAAA2C,SAAA,CAAAlD,IAAA;MAAA;IAAA,GAAA8C,QAAA;EAAA,CAC/B;EAAA,OAAAD,aAAA,CAAA3C,KAAA,OAAAC,SAAA;AAAA;AAED,SAASmC,cAAcA,CACrB1B,GAAa,EACbrD,MAAc,EACdgG,SAAiB,EACjBtH,QAAgB,EAChBsG,WAAoB,EACpBC,OAAkB,EAClBC,QAAmB;EAEnB,IAAMe,GAAG,GAAe;IACtB5C,GAAG,EAAHA,GAAG;IACHrD,MAAM,EAANA,MAAM;IACNgG,SAAS,EAATA,SAAS;IACTD,UAAU,EAAE,IAAIG,IAAI,EAAE;IACtBxH,QAAQ,EAARA;GACD;EAED,IAAIsG,WAAW,EAAE;IACfiB,GAAG,CAACjB,WAAW,GAAGA,WAAW;;EAG/B,IAAIC,OAAO,EAAE;IACXgB,GAAG,CAAChB,OAAO,GAAGA,OAAO;;EAGvB,IAAIC,QAAQ,EAAE;IACZe,GAAG,CAACf,QAAQ,GAAGA,QAAQ;;EAGzB,OAAOe,GAAG;AACZ;AAEA,SAASxE,OAAOA,CACduB,MAA+B,EAC/BzB,KAAsB,EACtBC,QAAwB,EACxBN,QAAwB;EAExB,IAAIiE,SAAS,CAACnC,MAAM,EAAE9B,QAAQ,CAAC,EAAE;IAC/B;;EAGF,IAAMiF,QAAQ,GAAGrG,MAAM,CAACsG,QAAQ,CAAC7E,KAAK,CAAC,GAAGA,KAAK,GAAGzB,MAAM,CAACuG,IAAI,CAAC9E,KAAK,EAAEC,QAAQ,CAAC;EAE9EwB,MAAM,CAAChD,MAAM,IAAImG,QAAQ,CAACnG,MAAM;EAEhC;EACA,IAAIgD,MAAM,CAAC9C,GAAG,GAAGiG,QAAQ,CAACnG,MAAM,GAAGgD,MAAM,CAACpD,cAAc,EAAE;IACxDuG,QAAQ,CAACG,IAAI,CAACtD,MAAM,CAACnD,UAAU,EAAEmD,MAAM,CAAC9C,GAAG,CAAC;IAC5C8C,MAAM,CAAC9C,GAAG,IAAIiG,QAAQ,CAACnG,MAAM;IAC7BmB,OAAO,CAACC,QAAQ,CAACF,QAAQ,CAAC;IAC1B;;EAGF;EACA;EACA,IAAIqF,iBAAiB,GAAGJ,QAAQ,CAACnG,MAAM;EACvC,IAAIwG,cAAc,GAAWxD,MAAM,CAACpD,cAAc,GAAGoD,MAAM,CAAC9C,GAAG;EAC/D,IAAIuG,SAAS,GAAGC,IAAI,CAACC,GAAG,CAACH,cAAc,EAAEL,QAAQ,CAACnG,MAAM,CAAC;EACzD,IAAIK,mBAAmB,GAAG,CAAC;EAC3B,OAAOkG,iBAAiB,GAAG,CAAC,EAAE;IAC5B,IAAMK,WAAW,GAAGT,QAAQ,CAACnG,MAAM,GAAGuG,iBAAiB;IACvDJ,QAAQ,CAACG,IAAI,CAACtD,MAAM,CAACnD,UAAU,EAAEmD,MAAM,CAAC9C,GAAG,EAAE0G,WAAW,EAAEA,WAAW,GAAGH,SAAS,CAAC;IAClFzD,MAAM,CAAC9C,GAAG,IAAIuG,SAAS;IACvBD,cAAc,IAAIC,SAAS;IAC3B,IAAIjB,GAAgB;IACpB,IAAIgB,cAAc,KAAK,CAAC,EAAE;MACxBhB,GAAG,GAAGtC,cAAc,CAACF,MAAM,CAACtD,EAAE,EAAEsD,MAAM,CAAC/C,CAAC,EAAEH,MAAM,CAACuG,IAAI,CAACrD,MAAM,CAACnD,UAAU,CAAC,CAAC;MACzE,EAAEmD,MAAM,CAAC7C,KAAK,CAACE,mBAAmB;MAClC,EAAEA,mBAAmB;MAErB,IAAI8E,SAAS,CAACnC,MAAM,EAAE9B,QAAQ,CAAC,EAAE;QAC/B;;MAGF8B,MAAM,CAAC/D,MAAM,CAACmG,SAAS,CAACI,GAAG,EAAE;QAAElG,YAAY,EAAE0D,MAAM,CAAC1D;MAAY,CAAE,CAAC,CAACqB,IAAI,CACtE,YAAK;QACH,EAAEqC,MAAM,CAAC7C,KAAK,CAACE,mBAAmB;QAClC,EAAEA,mBAAmB;QAErB,IAAI,CAACA,mBAAmB,EAAE;UACxByE,SAAS,CAAC9B,MAAM,EAAE9B,QAAQ,CAAC;;MAE/B,CAAC,EACD,UAAA+B,KAAK;QAAA,OAAIF,WAAW,CAACC,MAAM,EAAEC,KAAK,EAAE/B,QAAQ,CAAC;MAAA,EAC9C;MAEDsF,cAAc,GAAGxD,MAAM,CAACpD,cAAc;MACtCoD,MAAM,CAAC9C,GAAG,GAAG,CAAC;MACd,EAAE8C,MAAM,CAAC/C,CAAC;;IAEZsG,iBAAiB,IAAIE,SAAS;IAC9BA,SAAS,GAAGC,IAAI,CAACC,GAAG,CAACH,cAAc,EAAED,iBAAiB,CAAC;;AAE3D;AAEA,SAAS5E,YAAYA,CAACqB,MAA+B,EAAE9B,QAAkB;EACvE;EACA,IAAI8B,MAAM,CAAC9C,GAAG,KAAK,CAAC,EAAE;IACpB,OAAO4E,SAAS,CAAC9B,MAAM,EAAE9B,QAAQ,CAAC;;EAGpC,EAAE8B,MAAM,CAAC7C,KAAK,CAACE,mBAAmB;EAElC;EACA;EACA,IAAMwG,OAAO,GAAG/G,MAAM,CAACC,KAAK,CAACiD,MAAM,CAAC9C,GAAG,CAAC;EACxC8C,MAAM,CAACnD,UAAU,CAACyG,IAAI,CAACO,OAAO,EAAE,CAAC,EAAE,CAAC,EAAE7D,MAAM,CAAC9C,GAAG,CAAC;EACjD,IAAMsF,GAAG,GAAGtC,cAAc,CAACF,MAAM,CAACtD,EAAE,EAAEsD,MAAM,CAAC/C,CAAC,EAAE4G,OAAO,CAAC;EAExD;EACA,IAAI1B,SAAS,CAACnC,MAAM,EAAE9B,QAAQ,CAAC,EAAE;IAC/B;;EAGF8B,MAAM,CAAC/D,MAAM,CAACmG,SAAS,CAACI,GAAG,EAAE;IAAElG,YAAY,EAAE0D,MAAM,CAAC1D;EAAY,CAAE,CAAC,CAACqB,IAAI,CACtE,YAAK;IACH,EAAEqC,MAAM,CAAC7C,KAAK,CAACE,mBAAmB;IAClCyE,SAAS,CAAC9B,MAAM,EAAE9B,QAAQ,CAAC;EAC7B,CAAC,EACD,UAAA+B,KAAK;IAAA,OAAIF,WAAW,CAACC,MAAM,EAAEC,KAAK,EAAE/B,QAAQ,CAAC;EAAA,EAC9C;AACH;AAEA,SAASiE,SAASA,CAACnC,MAA+B,EAAE9B,QAAwB;EAC1E,IAAI8B,MAAM,CAAC7C,KAAK,CAACI,OAAO,EAAE;IACxBY,OAAO,CAACC,QAAQ,CAACF,QAAQ,EAAE,IAAIhD,OAAA,CAAAoE,aAAa,CAAC,yBAAyB,CAAC,CAAC;IACxE,OAAO,IAAI;;EAEb,OAAO,KAAK;AACd"},"metadata":{},"sourceType":"script","externalDependencies":[]}